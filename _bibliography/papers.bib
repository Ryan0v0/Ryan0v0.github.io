@article{Li_Liu_Zong_Zhao_Zhang_Song_2020, selected={true}, title={Graph Attention Based Proposal 3D ConvNets for Action Detection}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/5893}, DOI={10.1609/aaai.v34i04.5893}, abstractNote={&lt;p&gt;The recent advances in 3D Convolutional Neural Networks (3D CNNs) have shown promising performance for untrimmed video action detection, employing the popular detection framework that heavily relies on the temporal action proposal generations as the input of the action detector and localization regressor. In practice the proposals usually contain strong intra and inter relations among them, mainly stemming from the temporal and spatial variations in the video actions. However, most of existing 3D CNNs ignore the relations and thus suffer from the redundant proposals degenerating the detection performance and efficiency. To address this problem, we propose graph attention based proposal 3D ConvNets (AGCN-P-3DCNNs) for video action detection. Specifically, our proposed graph attention is composed of intra attention based GCN and inter attention based GCN. We use intra attention to learn the intra long-range dependencies inside each action proposal and update node matrix of Intra Attention based GCN, and use inter attention to learn the inter dependencies between different action proposals as adjacency matrix of Inter Attention based GCN. Afterwards, we fuse intra and inter attention to model intra long-range dependencies and inter dependencies simultaneously. Another contribution is that we propose a simple and effective framewise classifier, which enhances the feature presentation capabilities of backbone model. Experiments on two proposal 3D ConvNets based models (P-C3D and P-ResNet) and two popular action detection benchmarks (THUMOS 2014, ActivityNet v1.3) demonstrate the state-of-the-art performance achieved by our method. Particularly, P-C3D embedded with our module achieves average mAP 3.7% improvement on THUMOS 2014 dataset compared to original model.&lt;/p&gt;}, number={04}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Li, Jin and Liu, Xianglong and Zong, Zhuofan and Zhao, Wanru and Zhang, Mingyuan and Song, Jingkuan}, year={2020}, month={Apr.}, pages={4626-4633} }

@INPROCEEDINGS{9479849,
  author={Guo, Ruoxi and Cui, Jiahao and Zhao, Wanru and Li, Shuai},
  booktitle={2020 International Conference on Virtual Reality and Visualization (ICVRV)}, 
  title={AI and AR Based Interface for Piano Training}, 
  selected={true},
  year={2020},
  volume={},
  number={},
  pages={328-330},
  doi={10.1109/ICVRV51359.2020.00087}}



@INPROCEEDINGS{9419239,
  author={Guo, Ruoxi and Cui, Jiahao and Zhao, Wanru and Li, Shuai and Hao, Aimin},
  booktitle={2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Hand-by-Hand Mentor: An AR based Training System for Piano Performance}, 
  year={2021},
  selected={true},
  volume={},
  number={},
  pages={436-437},
  doi={10.1109/VRW52623.2021.00100}}


@inproceedings{Zhao_2022,
	doi = {10.1145/3556557.3557950},
  	selected={true},
	url = {https://doi.org/10.1145%2F3556557.3557950},
  
	year = 2022,
	month = {oct},
  
	publisher = {{ACM}
},
  
	author = {Wanru Zhao and Xinchi Qiu and Javier Fernandez-Marques and Pedro P. B. de Gusm{\~{a}}o and Nicholas D. Lane},
  
	title = {Protea: Client Profiling within Federated Systems using Flower},
  
	booktitle = {Proceedings of the 1st {ACM} Workshop on Data Privacy and Federated Learning Technologies for Mobile Edge Network}
}


@misc{chan2023harms,
      title={Harms from Increasingly Agentic Algorithmic Systems}, 
      author={Alan Chan and Rebecca Salganik and Alva Markelius and Chris Pang and Nitarshan Rajkumar and Dmitrii Krasheninnikov and Lauro Langosco and Zhonghao He and Yawen Duan and Micah Carroll and Michelle Lin and Alex Mayhew and Katherine Collins and Maryam Molamohammadi and John Burden and Wanru Zhao and Shalaleh Rismani and Konstantinos Voudouris and Umang Bhatt and Adrian Weller and David Krueger and Tegan Maharaj},
      year={2023},
      eprint={2302.10329},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      selected={true}
}